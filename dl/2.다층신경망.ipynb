{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff36bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba51f7f",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "- 픽셀값을 0 ~ 1 사이로 스케일링\n",
    "- 2차원 배열을 1차원 배열로 변환\n",
    "- 훈련, 검증 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed47f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = x_train / 255\n",
    "scaled_train = scaled_train.reshape(-1, 28 * 28)\n",
    "scaled_train, scaled_val, y_train, y_val = train_test_split(scaled_train, y_train,\n",
    "                                                            test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410202b",
   "metadata": {},
   "source": [
    "# 심층신경망 구성\n",
    "\n",
    "- 인공신경망에 층을 추가한 구조\n",
    "\n",
    "<img src = \"./image/ml_perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb05d2",
   "metadata": {},
   "source": [
    "- 단층 신경망과의 차이는 입력층과 출력층 사이에 밀집층이 추가된 것\n",
    "    - 입력층과 출력층 사이에 있는 모든 층을 은닉층(hidden layer)\n",
    "    \n",
    "- 출력층에 적용하는 활성화 함수와 은닉층에 적용하는 활성화 함수는 차이가 있음\n",
    "    - 출력층의 활성화 함수\n",
    "        - 출력층 함수라고도 부름\n",
    "        - 결과물을 적절한 형식으로 출력하도록 유도해서, 데이터셋과 잘 비교할 수 있도록 하는 역할\n",
    "        - 종류에 제한이 있음(이진분류 : 시그모이드, 다중 분류 : 소프트맥스)\n",
    "        \n",
    "    - 은닉층의 활성화 함수\n",
    "        - 여러 겹의 layer들 사이에서 사용됨\n",
    "        - 출력층 함수에 비해 선택이 자유로움\n",
    "        - 대표적인 활성화 함수 : ReLU(렐루)\n",
    "        - 모든 신경망의 은닉층에는 항상 활성화 함수가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6655d",
   "metadata": {},
   "source": [
    "- 활성화 함수(activation function)\n",
    "\n",
    "<img src = \"./image/activation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e82ef",
   "metadata": {},
   "source": [
    "- 활성화 함수를 쓰는 이유\n",
    "    - 예) a x 4 + 2 = b\n",
    "    - b x 3 - 5 = c\n",
    "    - 위 2개의 식은 a x 12 + 1 = c 로 단순화가 가능\n",
    "    \n",
    "- 은닉층이 선형적인 산술계산만 한다면 층이 깊어지더라도 계산식이 단순화되어 학습 효율이 떨어짐\n",
    "    - 따라서 활성화함수로 선형계산을 비선형 계산으로 비틀어주는 과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e258d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층\n",
    "dense1 = keras.layers.Dense(100, activation = \"sigmoid\", input_shape = (784,))\n",
    "\n",
    "# 출력층\n",
    "dense2 = keras.layers.Dense(10, activation = \"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be074de0",
   "metadata": {},
   "source": [
    "- dense1\n",
    "    - 은닉층\n",
    "    - 100개의 유닛을 가진 밀집층\n",
    "        - 유닛 개수를 정하는 것은 특별한 기준이 없음\n",
    "        - 다만, 출력층의 유닛보다는 많은 것이 좋음\n",
    "            - 은닉층의 유닛이 출력층보다 적다면 전달되는 정보량이 부족해질 수 있음\n",
    "    - 활성화 함수는 시그모이드\n",
    "    - 입력층과 연결되기 때문에 입력의 크기는 (784,)\n",
    "    \n",
    "- dense2\n",
    "    - 출력층\n",
    "    - 10개의 클래스로 분류하므로 10개의 유닛\n",
    "    - 다중 분류이기 때문에 활성화 함수는 소프트맥스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4682ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3634dde",
   "metadata": {},
   "source": [
    "- **가장 처음 등장하는 은닉층부터 마지막 출력층까지 순서대로 추가해야함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f87756",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(dense1)\n",
    "model.add(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455a8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30814047",
   "metadata": {},
   "source": [
    "- 모델 요약 정보\n",
    "    - 모델에 포함된 층들이 순서대로 나열됨\n",
    "        - 첫 은닉층부터 출력층까지\n",
    "    - 층 마다 이름, 클래스, 출력 크기, 파라미터 개수가 나옴\n",
    "        - 이름\n",
    "            - 층을 만들때 name 매개변수로 지정 가능\n",
    "            - 지정하지 않으면 기본값 \"dense\"\n",
    "        - Output Shape\n",
    "            - 출력 크기\n",
    "            - (None, 100)\n",
    "                - 첫 번째 차원은 샘플의 개수를 의미\n",
    "                - 샘플의 개수가 None인 이유는 한 번에 몇 개의 이미지씩 사용할 지 알 수 없기 때문에 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정\n",
    "                    - 케라스는 기본적으로 미니배치 경사하강법을 사용\n",
    "                    - batch_size를 설정하지 않으면 기본값 32\n",
    "                    - 따라서 input_shape나 output_shape의 첫 번째 차원을 배치 차원 이라고도 부름\n",
    "                    \n",
    "                - 두 번째 차원은 출력 개수\n",
    "                    - 100개의 유닛에서 결과가 나오기 때문에 출력 개수가 100\n",
    "                    - 즉, 각 이미지마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축됨\n",
    "        - Param\n",
    "            - 모델 파라미터 개수\n",
    "            - dense층\n",
    "                - 784픽셀의 입력값과 100개의 유닛의 모든 조합에 대한 가중치 + 각 유닛의 절편 1개씩\n",
    "                    - 784 * 100 + 100 = 78500\n",
    "            - dense_1층\n",
    "                - 앞 은닉층의 100개의 유닛과 10개의 출력층 유닛의 모든 조합에 대한 가중치 + 각 유닛의 절편 1개씩\n",
    "                    - 100 * 10 + 10 = 1010\n",
    "                    \n",
    "        - Non-trainable params\n",
    "            - 훈련되지 않는 파라미터\n",
    "            - 경사하강법으로 훈련되지 않는 파라미터를 가진 층이 있다면 여기에 표시됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f92bd",
   "metadata": {},
   "source": [
    "## 층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb5bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation = \"sigmoid\", input_shape = (784,), name = \"hidden\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\", name = \"output\")\n",
    "], name = \"Fashion_MNIST_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7021a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashion_MNIST_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c34d9",
   "metadata": {},
   "source": [
    "- 여러 모델과 많은 층을 사용할 때 구분을 위해서 name 매개변수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30b00d",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73f127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5675 - accuracy: 0.8062\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4100 - accuracy: 0.8525\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3759 - accuracy: 0.8642\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3517 - accuracy: 0.8745\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3352 - accuracy: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0bdd92920>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\n",
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e01e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3527676463127136, 0.871999979019165]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7fa5c0",
   "metadata": {},
   "source": [
    "- 은닉층의 추가로 훈련 세트에 대한 성능이 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2aeb8",
   "metadata": {},
   "source": [
    "# 활성화 함수\n",
    "\n",
    "- 초창기 인공신경망의 은닉층에서 많이 사용된 활성화 함수는 시그모이드\n",
    "<img src = \"./image/sigmoid.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b08a7b",
   "metadata": {},
   "source": [
    "- 입력값이 아무리 크더라도 0 ~ 1 사이의 값으로 출력되어 출력값의 범위가 너무 좁음\n",
    "    - 경사하강법 수행시에 기울기가 0에 수렴하는 기울기 소실(Gradient Vanishing)이 발생할 수 있음\n",
    "    - 층이 많아지고 모델이 복잡해질수록 그 효과가 누적되어 더욱 학습을 어렵게 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cfeae",
   "metadata": {},
   "source": [
    "## 렐루 함수(ReLU)\n",
    "\n",
    "<img src = \"./image/relu.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9bfca",
   "metadata": {},
   "source": [
    "- 입력이 양수일 경우 마치 활성화 함수가 없는 것 처럼 그냥 입력을 통과시키고, 음수일 경우에는 0이 됨\n",
    "- 표현식 : max(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586cf58",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "- 지금까지는 패션MNIST 데이터가 28 * 28 크기이기 때문에 인공신경망에 주입하기 전에 reshape를 이용하여 1차원으로 펼쳤음\n",
    "\n",
    "- 같은 기능을 위해서 케라스에서는 Flatten층을 제공함\n",
    "    - 샘플의 개수 차원을 제외하고 나머지 모든 입력 차원을 일렬로 펼쳐주는 역할\n",
    "    - 가중치나 절편이 없음\n",
    "    - 하지만 입력층과 은닉층 사이에 추가하기 때문에 편의상 '층' 이라고 부르지만 신경망의 깊이가 깊어진 것으로 보지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e5c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0cf179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5659503",
   "metadata": {},
   "source": [
    "- Flatten 층의 파라미터는 0\n",
    "- Flatten 층을 추가하면 입력값의 차원을 짐작할 수 있는 것이 장점\n",
    "    - 784개의 입력이 첫 번째 은닉층에 전달된다는 것이 명확하게 드러남\n",
    "- 입력 데이터에 대한 전처리 과정을 가능한한 모델에 포함시키는 것이 케라스API의 철학 중 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e5ca1",
   "metadata": {},
   "source": [
    "# 새 모델을 위한 데이터를 다시 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f4cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "scaled_train = x_train / 255\n",
    "scaled_train, scaled_val, y_train, y_val = train_test_split(scaled_train, y_train,\n",
    "                                                            test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f4f1fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8721adcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5281 - accuracy: 0.8127\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3955 - accuracy: 0.8575\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3581 - accuracy: 0.8725\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3366 - accuracy: 0.8797\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3220 - accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0c459dff0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\n",
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e7bbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3889019787311554, 0.8612499833106995]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb283672",
   "metadata": {},
   "source": [
    "# 딥러닝의 하이퍼파라미터\n",
    "\n",
    "- 하이퍼파라미터 : 모델이 학습하지 않아 사람이 지정해 주어야하는 파라미터\n",
    "- 인공신경망에서 하이퍼파라미터의 종류\n",
    "    - 은닉층의 개수\n",
    "    - 은닉층의 유닛 개수\n",
    "    - 활성화 함수\n",
    "    - 층의 종류\n",
    "        - 밀집층, CNN, RNN\n",
    "    - 미니배치 개수(batch_size)\n",
    "    - 반복 횟수(epochs)\n",
    "    - 옵티마이저(optimizer)\n",
    "    - 옵티마이저의 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc64228",
   "metadata": {},
   "source": [
    "## 옵티마이저\n",
    "\n",
    "- 케라스에서는 기본적으로 경사하강법 알고리즘을 사용\n",
    "- 케라스는 다양한 경사하강법 알고리즘을 제공하고, 이를 옵티마이저 라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e50fbb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd 옵티마이저를 사용하려면\n",
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1816d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 동일한 코드\n",
    "# 원래는 위의 코드처럼 각각의 클래스 객체를 만들어서 사용하는 것이 정석\n",
    "# 번거로움을 피하기 위해 \"sgd\"라고 입력하면 자동으로 SGD클래스 객체를 생성해줌\n",
    "model.compile(optimizer = \"sgd\", loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd701edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저의 학습률을 조절하고 싶다면\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26625a92",
   "metadata": {},
   "source": [
    "### 옵티마이저의 종류\n",
    "\n",
    "<img src = \"./image/optimizer.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f7aa6",
   "metadata": {},
   "source": [
    "- Momentum\n",
    "    - SGD클래스에서 momentum 기본값은 0\n",
    "    - momentum을 0보다 큰 값으로 지정하면 모멘텀 최적화(momentum optimization)을 사용\n",
    "    - 일반적으로 momentum 매개변수는 0.9 이상을 지정\n",
    "    \n",
    "- NAG(Nesterov Accelerated Gradient)\n",
    "    - SGD클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면 네스테로프 모멘텀 최적화를 사용할 수 있음\n",
    "    - 대부분의 경우 네스테로프 모멘텀 최적화가 기본 경사하강법보다는 더 나은 성능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c18e0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "nag = keras.optimizers.SGD(momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81698a9d",
   "metadata": {},
   "source": [
    "- 적응적 학습률(adaptive learning rate)\n",
    "    - 모델이 최적점에 가까이 갈수록 학습률을 낮춤\n",
    "        - 안정적으로 최적점에 수렴할 가능성이 높음\n",
    "    - 적응적 학습률을 사용하는 대표적인 옵티마이저\n",
    "        - Adagrad, RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc0316a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "\n",
    "# RMSprop\n",
    "rmsprop = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07d392",
   "metadata": {},
   "source": [
    "- 위의 모멘텀 최적화와 적응적 학습률을 접목한 것이 Adam\n",
    "    - 기본적으로 가장 많이 쓰이는 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e37c9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837b70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d54c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5253 - accuracy: 0.8161\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3914 - accuracy: 0.8586\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3530 - accuracy: 0.8736\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3266 - accuracy: 0.8804\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3075 - accuracy: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0c4ec25f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "166f6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34089964628219604, 0.8762500286102295]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae2566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
